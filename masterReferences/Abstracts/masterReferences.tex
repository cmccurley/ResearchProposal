\documentclass[]{article}

\usepackage[margin=1in]{geometry}
\usepackage[round]{natbib}
\usepackage{indentfirst}
\usepackage[hidelinks,pdfnewwindow=true]{hyperref}
\usepackage[dvipsnames]{xcolor}

%the following allows 5 deep section headings (can be useful for dividing things up)
%section
%  subsection
%    subsubsection
%      paragraph
%        subparagraph
\setcounter{secnumdepth}{5}
\setcounter{tocdepth}{5}

%defines list object
%inputs are
%[1] bibtex reference label
%[2] Paper title
%[3] pdf file name (folder is hard coded as ../References)
%[4] abstract or any text you want to add
\newcommand{\paperentry}[4]{
            \hangindent=1cm
            \cite{#1} - \href{run:../References/#3}{\textcolor{ForestGreen}{\textit{#2}}}
            
            \noindent            
            \begin{minipage}[t]{0.1\linewidth}\hfill\end{minipage}
            \begin{minipage}[t]{0.8\linewidth}\textcolor{NavyBlue}{{\textit{Summary:}}}#4\end{minipage}
            \vspace{.25cm}
          }

%opening
\title{List of References}

\author{Connor H. McCurley}

\date{}

\begin{document}

\maketitle

\tableofcontents

\newpage

\section{Army}
      
      \paperentry{Hall2019ProbabilisticObjectDetection}
      {Probabilistic Object Detection: Definition and Evaluation}
      {Army/Hall2019ProbabilisticObjectDetection.pdf}
      {A probabilistic object detection metric (PDQ - Probability-based Detection Quality) was proposed, thus defining the new task of defining probabilistic object detection metrics.  The ability of deep CNNs to quantify both \textit{epistemic} and \textit{aleatoric uncertainty} is paramount for deployment safety-critical applications.  PDQ aims to measure the accuracy of an image object detector in terms of its label uncertainty and spatial quality.  This is achieved through two steps.  First, a detector must reliably quantify its \textit{semantic uncertainty} by providing full probability distributions over known classes for each detection.  Next, the detectors must quantify spatial uncertainty by reporting \textit{probabilistic bounding boxes}, where the box corners are modeled as normally distributed.  A loss function was constructed to consider both label and spatial quality when providing a final detection measure.  The primary benefit of this method is that it provides a measure for the level of uncertainty in a detection. \\ \\ Is it possible to replace the probabilistic metric with a possibilistic one?  Could this be more effective at handling outlying cases?} 
      
      
      \paperentry{Mahalanobis2019DSIACCharacterization}
      {A comparison of target detection algorithms using DSIAC ATR algorithm development data set}
      {Army/Mahalanobis2019DSIACCharacterization.pdf}
      {The authors provided an initial characterization of detection performance on the DSIAC dataset using the \textit{Faster R-CNN} algorithm and \textit{Quadratic Correlation Filter (QCF)}.  Performance was evaluated on two datasets, ``easy'' and ``difficult'', where the difficulty was determined by number of pixels on target and local contrast.  Under difficult conditions, the Faster R-CNN algorithm achieved noteworthy performance, detecting as much as 80\% of the targets at a low false alarm rate of 0.01 FA/Square degree.  The dataset was limited by a lack of background diversity. }
      
      \paperentry{Tanner2019DSIACNeuralNet}
      {Fundamentals of Target Classification Using Deep Learning}
      {Army/Tanner2019DSIACNeuralNet.pdf}
      {A shallow CNN was utilized for ATR on the DSIAC MWIR dataset.  The goal of the study was to determine the range of optimal thresholds which would optimally separate the target and clutter class distributions defined by the CNN predictions (output of softmax), as well as determine an upper bound on the number of training images required for optimizing performance.  The shallow CNN (5 layers) and a Difference of Gaussians (DoG), which finds regions of high intensity on dark backgrounds were used to detect and classify targets.  The CNN could correctly classify 96\% of targets as targets and as few as 4\% of clutter as targets.  It was found that the DoG detector failed when the targets were small (long range) or if the overall image was bright (infrared taken during the daytime).  It was also determined that guessing the bright pixels were at the center of the targets was a bad assumption. (The brightest part of a target is not necessarily at its center.)}
      
\section{Manifold/ Representation Learning}

\section{Multiple Instance Learning}

\section{Fusion}


\section{Outlier/ Adversarial Detection}

\newpage

\bibliography{references}
\bibliographystyle{plainnat}

\end{document}
