\contentsline {extrachapter}{LIST OF TABLES}{5}{chapter*.2}
\contentsline {extrachapter}{LIST OF FIGURES}{6}{chapter*.3}
\addvspace {10pt}\noindent {CHAPTER}\hfill \par 
\contentsline {chapter}{LIST OF ABBREVIATIONS}{8}{chapter*.5}
\contentsline {chapter}{LIST OF SYMBOLS}{9}{chapter*.6}
\contentsline {chapter}{\numberline {1}\uppercase {Introduction}}{10}{chapter.1}
\contentsline {chapter}{\numberline {2}\uppercase {Background}}{22}{chapter.2}
\contentsline {section}{\numberline {2.1}Multiple Instance Learning}{22}{section.2.1}
\contentsline {subsection}{\numberline {2.1.1}Multiple Instance Learning with Manifold Bags}{23}{subsection.2.1.1}
\contentsline {subsection}{\numberline {2.1.2}Tasks}{24}{subsection.2.1.2}
\contentsline {subsection}{\numberline {2.1.3}Multiple Instance Classification}{24}{subsection.2.1.3}
\contentsline {subsubsection}{\numberline {2.1.3.1}Space Paradigms}{24}{subsubsection.2.1.3.1}
\contentsline {subsubsection}{\numberline {2.1.3.2}Instance-Space Classification}{25}{subsubsection.2.1.3.2}
\contentsline {paragraph}{Axis-Parallel Rectangle (APR)}{25}{section*.15}
\contentsline {paragraph}{Diverse Density (DD)}{25}{section*.16}
\contentsline {paragraph}{Expectation-Maximization Diverse Density (EM-DD)}{25}{section*.17}
\contentsline {paragraph}{MI-SVM}{25}{section*.18}
\contentsline {paragraph}{MIL-Boost}{25}{section*.19}
\contentsline {subsubsection}{\numberline {2.1.3.3}Bag-Space Classification}{26}{subsubsection.2.1.3.3}
\contentsline {paragraph}{Citation K-NN}{26}{section*.20}
\contentsline {paragraph}{MI-Graph}{26}{section*.21}
\contentsline {paragraph}{Neural Networks and Deep Learning}{26}{section*.22}
\contentsline {subsubsection}{\numberline {2.1.3.4}Embedded-Space Classification}{26}{subsubsection.2.1.3.4}
\contentsline {paragraph}{Multiple-Instance Learning via Embedded Instance Selection (MILES)}{26}{section*.23}
\contentsline {subsection}{\numberline {2.1.4}Multiple Instance Ranking}{26}{subsection.2.1.4}
\contentsline {subsection}{\numberline {2.1.5}Multiple Instance Boosting}{26}{subsection.2.1.5}
\contentsline {paragraph}{Gradient Boosting Overview}{26}{section*.24}
\contentsline {paragraph}{MIL-Boost}{27}{section*.25}
\contentsline {section}{\numberline {2.2}Manifold Learning}{28}{section.2.2}
\contentsline {subsection}{\numberline {2.2.1}Definition and General Notation}{30}{subsection.2.2.1}
\contentsline {subsection}{\numberline {2.2.2}Comparison Table of Manifold Learning Methods}{32}{subsection.2.2.2}
\contentsline {subsection}{\numberline {2.2.3}Geneology Image of Manifold Learning Methods from van der Maaten 2009, page 2}{32}{subsection.2.2.3}
\contentsline {subsection}{\numberline {2.2.4}Linear Manifold Learning}{32}{subsection.2.2.4}
\contentsline {subsubsection}{\numberline {2.2.4.1}Principal Component Analysis (PCA)}{32}{subsubsection.2.2.4.1}
\contentsline {paragraph}{Unsupervised PCA}{32}{section*.27}
\contentsline {subsubsection}{\numberline {2.2.4.2}Multi-Dimensional Scaling (MDS)}{34}{subsubsection.2.2.4.2}
\contentsline {paragraph}{Unsupervised MDS}{34}{section*.29}
\contentsline {paragraph}{Supervised MDS}{37}{section*.31}
\contentsline {subsubsection}{\numberline {2.2.4.3}Non-negative Matrix Factorization (NMF)}{38}{subsubsection.2.2.4.3}
\contentsline {subsubsection}{\numberline {2.2.4.4}Fisher's Linear Discriminant Analysis (LDA)}{38}{subsubsection.2.2.4.4}
\contentsline {paragraph}{Classical LDA}{38}{section*.32}
\contentsline {subsubsection}{\numberline {2.2.4.5}Locality Preserving Projection (LPP)}{41}{subsubsection.2.2.4.5}
\contentsline {subsection}{\numberline {2.2.5}Nonlinear Manifold Learning}{41}{subsection.2.2.5}
\contentsline {subsubsection}{\numberline {2.2.5.1}Kernelization}{41}{subsubsection.2.2.5.1}
\contentsline {paragraph}{Kernels}{41}{section*.35}
\contentsline {paragraph}{Kernel PCA}{43}{section*.36}
\contentsline {paragraph}{Kernel MDS}{43}{section*.37}
\contentsline {paragraph}{Kernel FDA (KDA)}{43}{section*.38}
\contentsline {subsubsection}{\numberline {2.2.5.2}Graph-based Methods}{44}{subsubsection.2.2.5.2}
\contentsline {paragraph}{Terminology}{44}{section*.39}
\contentsline {paragraph}{$\bm {K}$-Nearest Neighbor Graph}{45}{section*.41}
\contentsline {paragraph}{$\bm {\epsilon }$-Neighborhood Graph}{46}{section*.42}
\contentsline {paragraph}{Geodesic Distance Approximation}{46}{section*.43}
\contentsline {subsubsection}{\numberline {2.2.5.3}General Graph Embedding Framework}{47}{subsubsection.2.2.5.3}
\contentsline {subsubsection}{\numberline {2.2.5.4}Isomap}{47}{subsubsection.2.2.5.4}
\contentsline {paragraph}{Traditional Isomap}{47}{section*.45}
\contentsline {paragraph}{Supervised Isomap Approaches}{49}{section*.46}
\contentsline {subsubsection}{\numberline {2.2.5.5}Locally Linear Embedding (LLE)}{50}{subsubsection.2.2.5.5}
\contentsline {subsubsection}{\numberline {2.2.5.6}Laplacian Eigenmaps (LE)}{50}{subsubsection.2.2.5.6}
\contentsline {paragraph}{Classical LE}{50}{section*.47}
\contentsline {paragraph}{Supervised LE (S-LE)}{52}{section*.48}
\contentsline {subsubsection}{\numberline {2.2.5.7}Hessian Eigenmaps}{55}{subsubsection.2.2.5.7}
\contentsline {subsubsection}{\numberline {2.2.5.8}Diffusion Maps}{55}{subsubsection.2.2.5.8}
\contentsline {subsubsection}{\numberline {2.2.5.9}Sammon Mapping}{55}{subsubsection.2.2.5.9}
\contentsline {subsubsection}{\numberline {2.2.5.10}Maximum Variance Unfolding (MVU)}{55}{subsubsection.2.2.5.10}
\contentsline {subsection}{\numberline {2.2.6}Latent Variable Models}{55}{subsection.2.2.6}
\contentsline {subsubsection}{\numberline {2.2.6.1}General Latent Variable Model (GLVM)}{55}{subsubsection.2.2.6.1}
\contentsline {paragraph}{Factor Analysis (FA)}{55}{section*.49}
\contentsline {paragraph}{Probabilistic PCA (PPCA)}{56}{section*.50}
\contentsline {paragraph}{Supervised PCA}{56}{section*.51}
\contentsline {subparagraph}{Supervised PCA (Latent Factor Regression)}{57}{section*.52}
\contentsline {subparagraph}{Discriminative Supervised PCA}{57}{section*.53}
\contentsline {subsubsection}{\numberline {2.2.6.2}Generative Topographic Mapping (GTM)}{57}{subsubsection.2.2.6.2}
\contentsline {subsection}{\numberline {2.2.7}Competitive Hebbian Learning}{57}{subsection.2.2.7}
\contentsline {subsection}{\numberline {2.2.8}Deep Learning}{57}{subsection.2.2.8}
\contentsline {paragraph}{Autoencoders}{57}{section*.54}
\contentsline {paragraph}{Graph Convolutional Networks}{57}{section*.55}
\contentsline {paragraph}{M3DNet}{57}{section*.56}
\contentsline {paragraph}{Paper in Papers channel}{57}{section*.57}
\contentsline {subsection}{\numberline {2.2.9}Current State of the Art}{58}{subsection.2.2.9}
\contentsline {subsection}{\numberline {2.2.10}UMAP}{58}{subsection.2.2.10}
\contentsline {subsection}{\numberline {2.2.11}Stochastic Neighbor Embedding (SNE and t-SNE)}{58}{subsection.2.2.11}
\contentsline {subsection}{\numberline {2.2.12}NCA}{58}{subsection.2.2.12}
\contentsline {section}{\numberline {2.3}Weakly Supervised Manifold Learning and Dimensionality Reduction}{58}{section.2.3}
\contentsline {subsection}{\numberline {2.3.1}MIL-Based}{59}{subsection.2.3.1}
\contentsline {subsection}{\numberline {2.3.2}General Weak Supervision}{63}{subsection.2.3.2}
\contentsline {section}{\numberline {2.4}Metric Embedding}{64}{section.2.4}
\contentsline {subsubsection}{\numberline {2.4.0.1}Metric Learning}{65}{subsubsection.2.4.0.1}
\contentsline {subsubsection}{\numberline {2.4.0.2}Preference Learning}{66}{subsubsection.2.4.0.2}
\contentsline {subsection}{\numberline {2.4.1}Ranking Loss}{66}{subsection.2.4.1}
\contentsline {subsubsection}{\numberline {2.4.1.1}Pairwise Loss}{66}{subsubsection.2.4.1.1}
\contentsline {subsubsection}{\numberline {2.4.1.2}Contrastive Loss}{66}{subsubsection.2.4.1.2}
\contentsline {subsubsection}{\numberline {2.4.1.3}Triplet Loss}{66}{subsubsection.2.4.1.3}
\contentsline {subsubsection}{\numberline {2.4.1.4}Large-Margin K-Nearest Neighbors (LMNN)}{66}{subsubsection.2.4.1.4}
\contentsline {subsubsection}{\numberline {2.4.1.5}FaceNet}{66}{subsubsection.2.4.1.5}
\contentsline {subsubsection}{\numberline {2.4.1.6}Siamese Neural Networks}{66}{subsubsection.2.4.1.6}
\contentsline {subsection}{\numberline {2.4.2}Weakly Supervised Dimensionality Reduction with Metric Embedding}{66}{subsection.2.4.2}
\contentsline {subsection}{\numberline {2.4.3}Manifold Regularization}{67}{subsection.2.4.3}
\contentsline {subsection}{\numberline {2.4.4}Multiple Instance Metric Learning}{67}{subsection.2.4.4}
\contentsline {chapter}{\numberline {3}\uppercase {Problem Description}}{68}{chapter.3}
\contentsline {chapter}{\numberline {4}\uppercase {Experimental Design}}{69}{chapter.4}
\contentsline {chapter}{\numberline {5}\uppercase {Preliminary Work}}{70}{chapter.5}
\contentsline {chapter}{\numberline {6}\uppercase {Future Tasks}}{71}{chapter.6}
\contentsline {chapter}{\numberline {7}\uppercase {Conclusions}}{72}{chapter.7}
\addvspace {10pt}\noindent {APPENDIX} \hfill \par 
