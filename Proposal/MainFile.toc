\contentsline {extrachapter}{LIST OF TABLES}{5}{chapter*.2}
\contentsline {extrachapter}{LIST OF FIGURES}{6}{chapter*.3}
\addvspace {10pt}\noindent {CHAPTER}\hfill \par 
\contentsline {chapter}{LIST OF ABBREVIATIONS}{7}{chapter*.5}
\contentsline {chapter}{LIST OF SYMBOLS}{9}{chapter*.6}
\contentsline {chapter}{\numberline {1}\uppercase {Introduction}}{10}{chapter.1}
\contentsline {chapter}{\numberline {2}\uppercase {Background}}{21}{chapter.2}
\contentsline {section}{\numberline {2.1}Multiple Instance Learning}{21}{section.2.1}
\contentsline {subsection}{\numberline {2.1.1}Multiple Instance Learning with Manifold Bags}{22}{subsection.2.1.1}
\contentsline {subsection}{\numberline {2.1.2}Tasks}{23}{subsection.2.1.2}
\contentsline {subsection}{\numberline {2.1.3}Multiple Instance Classification}{23}{subsection.2.1.3}
\contentsline {subsubsection}{\numberline {2.1.3.1}Space Paradigms}{23}{subsubsection.2.1.3.1}
\contentsline {subsubsection}{\numberline {2.1.3.2}MIL Classification Approaches}{24}{subsubsection.2.1.3.2}
\contentsline {paragraph}{Learning Axis-Parallel Concepts:}{25}{section*.15}
\contentsline {paragraph}{Maximum Likelihood:}{25}{section*.16}
\contentsline {paragraph}{Distance-Based:}{26}{section*.17}
\contentsline {paragraph}{Maximum Margin:}{27}{section*.18}
\contentsline {paragraph}{Neural Networks and Deep Learning:}{28}{section*.19}
\contentsline {paragraph}{Probabilistic Graphical Methods:}{29}{section*.20}
\contentsline {paragraph}{Dictionary Learning:}{30}{section*.21}
\contentsline {paragraph}{Ensembles of Classifiers:}{31}{section*.22}
\contentsline {subsection}{\numberline {2.1.4}Multiple Instance Boosting (MIL-Boost)}{32}{subsection.2.1.4}
\contentsline {paragraph}{Gradient Boosting Overview}{32}{section*.23}
\contentsline {paragraph}{MIL-Boost}{32}{section*.24}
\contentsline {subsection}{\numberline {2.1.5}Multiple Instance Ranking}{34}{subsection.2.1.5}
\contentsline {section}{\numberline {2.2}Manifold Learning}{36}{section.2.2}
\contentsline {subsection}{\numberline {2.2.1}Definition and General Notation}{38}{subsection.2.2.1}
\contentsline {subsection}{\numberline {2.2.2}Comparison Table of Manifold Learning Methods}{39}{subsection.2.2.2}
\contentsline {subsection}{\numberline {2.2.3}Geneology Image of Manifold Learning Methods from van der Maaten 2009, page 2}{39}{subsection.2.2.3}
\contentsline {subsection}{\numberline {2.2.4}Linear Manifold Learning}{39}{subsection.2.2.4}
\contentsline {subsubsection}{\numberline {2.2.4.1}Principal Component Analysis (PCA)}{40}{subsubsection.2.2.4.1}
\contentsline {paragraph}{Unsupervised PCA}{40}{section*.26}
\contentsline {subsubsection}{\numberline {2.2.4.2}Multi-Dimensional Scaling (MDS)}{42}{subsubsection.2.2.4.2}
\contentsline {paragraph}{Unsupervised MDS}{42}{section*.28}
\contentsline {paragraph}{Supervised MDS}{44}{section*.30}
\contentsline {subsubsection}{\numberline {2.2.4.3}Non-negative Matrix Factorization (NMF)}{45}{subsubsection.2.2.4.3}
\contentsline {subsubsection}{\numberline {2.2.4.4}Fisher's Linear Discriminant Analysis (LDA)}{45}{subsubsection.2.2.4.4}
\contentsline {paragraph}{Classical LDA}{45}{section*.31}
\contentsline {subsubsection}{\numberline {2.2.4.5}Locality Preserving Projection (LPP)}{48}{subsubsection.2.2.4.5}
\contentsline {subsection}{\numberline {2.2.5}Nonlinear Manifold Learning}{48}{subsection.2.2.5}
\contentsline {subsubsection}{\numberline {2.2.5.1}Kernelization}{49}{subsubsection.2.2.5.1}
\contentsline {paragraph}{Kernels}{49}{section*.34}
\contentsline {paragraph}{Kernel PCA}{51}{section*.35}
\contentsline {paragraph}{Kernel MDS}{51}{section*.36}
\contentsline {paragraph}{Kernel FDA (KDA)}{51}{section*.37}
\contentsline {subsubsection}{\numberline {2.2.5.2}Graph-based Methods}{51}{subsubsection.2.2.5.2}
\contentsline {paragraph}{Terminology}{52}{section*.38}
\contentsline {paragraph}{$\bm {K}$-Nearest Neighbor Graph}{53}{section*.40}
\contentsline {paragraph}{$\bm {\epsilon }$-Neighborhood Graph}{54}{section*.41}
\contentsline {paragraph}{Geodesic Distance Approximation}{54}{section*.42}
\contentsline {subsubsection}{\numberline {2.2.5.3}General Graph Embedding Framework}{55}{subsubsection.2.2.5.3}
\contentsline {subsubsection}{\numberline {2.2.5.4}Isomap}{55}{subsubsection.2.2.5.4}
\contentsline {paragraph}{Traditional Isomap}{55}{section*.44}
\contentsline {paragraph}{Supervised Isomap Approaches}{57}{section*.45}
\contentsline {subsubsection}{\numberline {2.2.5.5}Locally Linear Embedding (LLE)}{58}{subsubsection.2.2.5.5}
\contentsline {subsubsection}{\numberline {2.2.5.6}Laplacian Eigenmaps (LE)}{58}{subsubsection.2.2.5.6}
\contentsline {paragraph}{Classical LE}{58}{section*.46}
\contentsline {paragraph}{Supervised LE (S-LE)}{60}{section*.47}
\contentsline {subsubsection}{\numberline {2.2.5.7}Hessian Eigenmaps}{63}{subsubsection.2.2.5.7}
\contentsline {subsubsection}{\numberline {2.2.5.8}Diffusion Maps}{63}{subsubsection.2.2.5.8}
\contentsline {subsubsection}{\numberline {2.2.5.9}Sammon Mapping}{63}{subsubsection.2.2.5.9}
\contentsline {subsubsection}{\numberline {2.2.5.10}Maximum Variance Unfolding (MVU)}{63}{subsubsection.2.2.5.10}
\contentsline {subsection}{\numberline {2.2.6}Latent Variable Models}{63}{subsection.2.2.6}
\contentsline {subsubsection}{\numberline {2.2.6.1}General Latent Variable Model (GLVM)}{63}{subsubsection.2.2.6.1}
\contentsline {paragraph}{Factor Analysis (FA)}{63}{section*.48}
\contentsline {paragraph}{Probabilistic PCA (PPCA)}{63}{section*.49}
\contentsline {paragraph}{Supervised PCA}{64}{section*.50}
\contentsline {subparagraph}{Supervised PCA (Latent Factor Regression)}{65}{section*.51}
\contentsline {subparagraph}{Discriminative Supervised PCA}{65}{section*.52}
\contentsline {subsubsection}{\numberline {2.2.6.2}Generative Topographic Mapping (GTM)}{65}{subsubsection.2.2.6.2}
\contentsline {subsection}{\numberline {2.2.7}Competitive Hebbian Learning}{65}{subsection.2.2.7}
\contentsline {subsection}{\numberline {2.2.8}Deep Learning}{65}{subsection.2.2.8}
\contentsline {paragraph}{Autoencoders}{65}{section*.53}
\contentsline {paragraph}{Graph Convolutional Networks}{65}{section*.54}
\contentsline {paragraph}{M3DNet}{65}{section*.55}
\contentsline {paragraph}{Paper in Papers channel}{65}{section*.56}
\contentsline {subsection}{\numberline {2.2.9}UMAP}{65}{subsection.2.2.9}
\contentsline {subsection}{\numberline {2.2.10}Stochastic Neighbor Embedding (SNE and t-SNE)}{65}{subsection.2.2.10}
\contentsline {subsection}{\numberline {2.2.11}NCA}{65}{subsection.2.2.11}
\contentsline {subsubsection}{\numberline {2.2.11.1}M3DNet}{65}{subsubsection.2.2.11.1}
\contentsline {section}{\numberline {2.3}Weakly Supervised Manifold Learning and Dimensionality Reduction}{65}{section.2.3}
\contentsline {subsection}{\numberline {2.3.1}MIDR}{67}{subsection.2.3.1}
\contentsline {subsection}{\numberline {2.3.2}MidLABS}{69}{subsection.2.3.2}
\contentsline {subsection}{\numberline {2.3.3}MIDA}{70}{subsection.2.3.3}
\contentsline {subsection}{\numberline {2.3.4}CLFDA}{71}{subsection.2.3.4}
\contentsline {subsection}{\numberline {2.3.5}MI-FEAR}{73}{subsection.2.3.5}
\contentsline {subsection}{\numberline {2.3.6}Comparison Table of MI Dimensionality Reduction Methods}{75}{subsection.2.3.6}
\contentsline {subsection}{\numberline {2.3.7}General Weak Supervision}{76}{subsection.2.3.7}
\contentsline {section}{\numberline {2.4}Metric Embedding}{78}{section.2.4}
\contentsline {subsection}{\numberline {2.4.1}Ranking Loss}{79}{subsection.2.4.1}
\contentsline {subsubsection}{\numberline {2.4.1.1}Contrastive Loss}{79}{subsubsection.2.4.1.1}
\contentsline {subsubsection}{\numberline {2.4.1.2}Triplet Loss}{80}{subsubsection.2.4.1.2}
\contentsline {subsection}{\numberline {2.4.2}Large-Margin K-Nearest Neighbors (LMNN)}{82}{subsection.2.4.2}
\contentsline {subsection}{\numberline {2.4.3}Siamese Neural Networks}{82}{subsection.2.4.3}
\contentsline {subsection}{\numberline {2.4.4}Triplet Networks}{82}{subsection.2.4.4}
\contentsline {chapter}{\numberline {3}\uppercase {Technical Approach}}{84}{chapter.3}
\contentsline {section}{\numberline {3.1}Nonlinear Manifold Learning for Bag-Level Classification}{84}{section.3.1}
\contentsline {section}{\numberline {3.2}Nonlinear Manifold Learning for Instance-Level Classification}{84}{section.3.2}
\contentsline {chapter}{\numberline {4}\uppercase {Experimental Design}}{85}{chapter.4}
\contentsline {subsection}{\numberline {4.0.1}Overview}{85}{subsection.4.0.1}
\contentsline {subsection}{\numberline {4.0.2}Description of Data}{85}{subsection.4.0.2}
\contentsline {subsection}{\numberline {4.0.3}Feature Extraction}{87}{subsection.4.0.3}
\contentsline {subsubsection}{\numberline {4.0.3.1}HOG Features}{88}{subsubsection.4.0.3.1}
\contentsline {subsubsection}{\numberline {4.0.3.2}CNN Features}{88}{subsubsection.4.0.3.2}
\contentsline {subsection}{\numberline {4.0.4}Algorithm Parameters}{90}{subsection.4.0.4}
\contentsline {subsection}{\numberline {4.0.5}Training and Testing Procedures}{90}{subsection.4.0.5}
\contentsline {paragraph}{Training}{90}{section*.63}
\contentsline {paragraph}{Out-of-Sample Testing}{90}{section*.64}
\contentsline {paragraph}{Evaluation Metrics}{90}{section*.65}
\contentsline {chapter}{\numberline {5}\uppercase {Preliminary Results}}{92}{chapter.5}
\contentsline {chapter}{\numberline {6}\uppercase {Future Tasks}}{93}{chapter.6}
\contentsline {subsection}{\numberline {6.0.1}Future Experiments}{93}{subsection.6.0.1}
\contentsline {subsubsection}{\numberline {6.0.1.1}Comparison to other methods}{94}{subsubsection.6.0.1.1}
\addvspace {10pt}\noindent {APPENDIX} \hfill \par 
