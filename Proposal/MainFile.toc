\contentsline {extrachapter}{LIST OF TABLES}{6}{chapter*.2}
\contentsline {extrachapter}{LIST OF FIGURES}{7}{chapter*.3}
\addvspace {10pt}\noindent {CHAPTER}\hfill \par 
\contentsline {chapter}{LIST OF ABBREVIATIONS}{8}{chapter*.5}
\contentsline {chapter}{LIST OF SYMBOLS}{10}{chapter*.6}
\contentsline {chapter}{\numberline {1}\uppercase {Introduction}}{11}{chapter.1}
\contentsline {chapter}{\numberline {2}\uppercase {Background}}{23}{chapter.2}
\contentsline {section}{\numberline {2.1}Multiple Instance Learning}{23}{section.2.1}
\contentsline {subsection}{\numberline {2.1.1}Multiple Instance Learning with Manifold Bags}{24}{subsection.2.1.1}
\contentsline {subsection}{\numberline {2.1.2}Tasks}{25}{subsection.2.1.2}
\contentsline {subsection}{\numberline {2.1.3}Multiple Instance Classification}{25}{subsection.2.1.3}
\contentsline {subsubsection}{\numberline {2.1.3.1}Space Paradigms}{25}{subsubsection.2.1.3.1}
\contentsline {subsubsection}{\numberline {2.1.3.2}MIL Classification Approaches}{26}{subsubsection.2.1.3.2}
\contentsline {paragraph}{Learning Axis-Parallel Concepts:}{27}{section*.15}
\contentsline {paragraph}{Maximum Likelihood:}{27}{section*.16}
\contentsline {paragraph}{Distance-Based:}{28}{section*.17}
\contentsline {paragraph}{Maximum Margin:}{29}{section*.18}
\contentsline {paragraph}{Neural Networks and Deep Learning:}{30}{section*.19}
\contentsline {paragraph}{Probabilistic Graphical Methods:}{31}{section*.20}
\contentsline {paragraph}{Dictionary Learning:}{32}{section*.21}
\contentsline {paragraph}{Ensembles of Classifiers:}{33}{section*.22}
\contentsline {subsection}{\numberline {2.1.4}Multiple Instance Boosting (MIL-Boost)}{34}{subsection.2.1.4}
\contentsline {paragraph}{Gradient Boosting Overview}{34}{section*.23}
\contentsline {paragraph}{MIL-Boost}{34}{section*.24}
\contentsline {subsection}{\numberline {2.1.5}Multiple Instance Ranking}{36}{subsection.2.1.5}
\contentsline {section}{\numberline {2.2}Manifold Learning}{38}{section.2.2}
\contentsline {subsection}{\numberline {2.2.1}Definition and General Notation}{40}{subsection.2.2.1}
\contentsline {subsection}{\numberline {2.2.2}Linear Manifold Learning}{41}{subsection.2.2.2}
\contentsline {subsubsection}{\numberline {2.2.2.1}Principal Component Analysis (PCA)}{41}{subsubsection.2.2.2.1}
\contentsline {paragraph}{Unsupervised PCA}{41}{section*.26}
\contentsline {paragraph}{Independent and Canoncial Component Analyses}{44}{section*.28}
\contentsline {subsubsection}{\numberline {2.2.2.2}Multi-Dimensional Scaling (MDS)}{44}{subsubsection.2.2.2.2}
\contentsline {paragraph}{Unsupervised MDS}{44}{section*.29}
\contentsline {paragraph}{Supervised MDS}{47}{section*.31}
\contentsline {subsubsection}{\numberline {2.2.2.3}Nonnegative Matrix Factorization (NMF)}{48}{subsubsection.2.2.2.3}
\contentsline {subsubsection}{\numberline {2.2.2.4}Fisher's Linear Discriminant Analysis (LDA)}{49}{subsubsection.2.2.2.4}
\contentsline {paragraph}{Classical LDA}{49}{section*.32}
\contentsline {subsection}{\numberline {2.2.3}Nonlinear Manifold Learning}{52}{subsection.2.2.3}
\contentsline {subsubsection}{\numberline {2.2.3.1}Kernelization}{52}{subsubsection.2.2.3.1}
\contentsline {paragraph}{Kernels}{52}{section*.35}
\contentsline {subsubsection}{\numberline {2.2.3.2}Kernel PCA (KPCA)}{54}{subsubsection.2.2.3.2}
\contentsline {subsubsection}{\numberline {2.2.3.3}Graph-based Methods}{57}{subsubsection.2.2.3.3}
\contentsline {paragraph}{Terminology}{57}{section*.36}
\contentsline {paragraph}{$\bm {K}$-Nearest Neighbor Graph}{58}{section*.38}
\contentsline {paragraph}{$\bm {\epsilon }$-Neighborhood Graph}{59}{section*.39}
\contentsline {paragraph}{Geodesic Distance Approximation}{60}{section*.40}
\contentsline {subsubsection}{\numberline {2.2.3.4}Isomap}{60}{subsubsection.2.2.3.4}
\contentsline {paragraph}{Traditional Isomap}{60}{section*.42}
\contentsline {paragraph}{Supervised Isomap Approaches}{62}{section*.43}
\contentsline {subsubsection}{\numberline {2.2.3.5}Sammon Mapping}{64}{subsubsection.2.2.3.5}
\contentsline {subsubsection}{\numberline {2.2.3.6}Maximum Variance Unfolding (MVU)}{65}{subsubsection.2.2.3.6}
\contentsline {subsubsection}{\numberline {2.2.3.7}Locally Linear Embedding (LLE)}{66}{subsubsection.2.2.3.7}
\contentsline {subsubsection}{\numberline {2.2.3.8}Laplacian Eigenmaps (LE)}{67}{subsubsection.2.2.3.8}
\contentsline {paragraph}{Classical LE}{67}{section*.44}
\contentsline {paragraph}{Linear LE (LPP)}{69}{section*.45}
\contentsline {paragraph}{Supervised LE (S-LE)}{69}{section*.46}
\contentsline {subsubsection}{\numberline {2.2.3.9}Hessian LLE}{73}{subsubsection.2.2.3.9}
\contentsline {subsubsection}{\numberline {2.2.3.10}Local Tangent Space Alignment (LTSA)}{74}{subsubsection.2.2.3.10}
\contentsline {subsubsection}{\numberline {2.2.3.11}Diffusion Maps}{75}{subsubsection.2.2.3.11}
\contentsline {subsection}{\numberline {2.2.4}Principal Curves, Surfaces and Manifolds}{76}{subsection.2.2.4}
\contentsline {subsubsection}{\numberline {2.2.4.1}Deep Learning}{77}{subsubsection.2.2.4.1}
\contentsline {paragraph}{Autoencoders and Nonlinear PCA}{78}{section*.47}
\contentsline {paragraph}{Graph Convolutional Networks}{80}{section*.49}
\contentsline {subsubsection}{\numberline {2.2.4.2}Self-Organizing Map (SOM)}{80}{subsubsection.2.2.4.2}
\contentsline {subsubsection}{\numberline {2.2.4.3}Growing Neural Gas (GNG)}{83}{subsubsection.2.2.4.3}
\contentsline {subsubsection}{\numberline {2.2.4.4}Elastic Maps and Nets}{83}{subsubsection.2.2.4.4}
\contentsline {subsection}{\numberline {2.2.5}Probabilistic Latent Variable Models (LVM)}{85}{subsection.2.2.5}
\contentsline {subsubsection}{\numberline {2.2.5.1}Factor Analysis (FA) and Probabilistic PCA (PPCA)}{85}{subsubsection.2.2.5.1}
\contentsline {paragraph}{Supervised PCA}{87}{section*.50}
\contentsline {subparagraph}{Supervised PCA (Latent Factor Regression)}{87}{section*.51}
\contentsline {subparagraph}{Discriminative Supervised PCA}{87}{section*.52}
\contentsline {subsubsection}{\numberline {2.2.5.2}Gaussian Process Latent Variable Model (GPLVM)}{88}{subsubsection.2.2.5.2}
\contentsline {subsubsection}{\numberline {2.2.5.3}Generative Topographic Mapping (GTM)}{88}{subsubsection.2.2.5.3}
\contentsline {subsubsection}{\numberline {2.2.5.4}Manifold Charting}{89}{subsubsection.2.2.5.4}
\contentsline {subsection}{\numberline {2.2.6}High-Dimensional Data Visualization}{90}{subsection.2.2.6}
\contentsline {subsubsection}{\numberline {2.2.6.1}Stochastic Neighbor Embedding (SNE and t-SNE)}{91}{subsubsection.2.2.6.1}
\contentsline {subsubsection}{\numberline {2.2.6.2}LargeVis}{93}{subsubsection.2.2.6.2}
\contentsline {subsubsection}{\numberline {2.2.6.3}Uniform Manifold Approximation and Projection (UMAP)}{94}{subsubsection.2.2.6.3}
\contentsline {subsection}{\numberline {2.2.7}Discussion}{97}{subsection.2.2.7}
\contentsline {subsubsection}{\numberline {2.2.7.1}Overview of Unsupervised Manifold Learning Methods}{97}{subsubsection.2.2.7.1}
\contentsline {subsubsection}{\numberline {2.2.7.2}Relations}{100}{subsubsection.2.2.7.2}
\contentsline {subsubsection}{\numberline {2.2.7.3}Strengths and Weaknesses}{100}{subsubsection.2.2.7.3}
\contentsline {section}{\numberline {2.3}Weakly Supervised Manifold Learning and Dimensionality Reduction}{100}{section.2.3}
\contentsline {subsection}{\numberline {2.3.1}MIDR}{102}{subsection.2.3.1}
\contentsline {subsection}{\numberline {2.3.2}MidLABS}{104}{subsection.2.3.2}
\contentsline {subsection}{\numberline {2.3.3}MIDA}{106}{subsection.2.3.3}
\contentsline {subsection}{\numberline {2.3.4}CLFDA}{107}{subsection.2.3.4}
\contentsline {subsection}{\numberline {2.3.5}MI-FEAR}{109}{subsection.2.3.5}
\contentsline {subsection}{\numberline {2.3.6}Comparison Table of MI Dimensionality Reduction Methods}{110}{subsection.2.3.6}
\contentsline {subsection}{\numberline {2.3.7}General Weak Supervision}{111}{subsection.2.3.7}
\contentsline {section}{\numberline {2.4}Metric Embedding}{113}{section.2.4}
\contentsline {subsection}{\numberline {2.4.1}Ranking Loss}{114}{subsection.2.4.1}
\contentsline {subsubsection}{\numberline {2.4.1.1}Contrastive Loss}{114}{subsubsection.2.4.1.1}
\contentsline {subsubsection}{\numberline {2.4.1.2}Triplet Loss}{115}{subsubsection.2.4.1.2}
\contentsline {subsection}{\numberline {2.4.2}Large-Margin K-Nearest Neighbors (LMNN)}{117}{subsection.2.4.2}
\contentsline {subsection}{\numberline {2.4.3}Siamese Neural Networks}{119}{subsection.2.4.3}
\contentsline {subsection}{\numberline {2.4.4}FaceNet}{121}{subsection.2.4.4}
\contentsline {chapter}{\numberline {3}\uppercase {Technical Approach}}{122}{chapter.3}
\contentsline {section}{\numberline {3.1}Preliminary Work}{122}{section.3.1}
\contentsline {subsection}{\numberline {3.1.1}S-LE Algorithm Description}{123}{subsection.3.1.1}
\contentsline {subsection}{\numberline {3.1.2}SE-Isomap Algorithm Description}{123}{subsection.3.1.2}
\contentsline {subsection}{\numberline {3.1.3}Instance-Level Classification}{125}{subsection.3.1.3}
\contentsline {section}{\numberline {3.2}Future Work}{125}{section.3.2}
\contentsline {subsection}{\numberline {3.2.1}Instance Selection}{126}{subsection.3.2.1}
\contentsline {subsection}{\numberline {3.2.2}Manifold Learning}{126}{subsection.3.2.2}
\contentsline {subsection}{\numberline {3.2.3}Metric Embedding}{126}{subsection.3.2.3}
\contentsline {subsection}{\numberline {3.2.4}Out-of-Sample Testing}{127}{subsection.3.2.4}
\contentsline {subsection}{\numberline {3.2.5}Comparison to SOA}{128}{subsection.3.2.5}
\contentsline {section}{\numberline {3.3}Datasets}{129}{section.3.3}
\contentsline {chapter}{\numberline {4}\uppercase {Experimental Design}}{131}{chapter.4}
\contentsline {subsection}{\numberline {4.0.1}Overview}{131}{subsection.4.0.1}
\contentsline {subsection}{\numberline {4.0.2}Description of Data}{132}{subsection.4.0.2}
\contentsline {subsubsection}{\numberline {4.0.2.1}Quadratic Surfaces}{132}{subsubsection.4.0.2.1}
\contentsline {subsubsection}{\numberline {4.0.2.2}DSIAC MS-003-DB}{132}{subsubsection.4.0.2.2}
\contentsline {subsection}{\numberline {4.0.3}Feature Extraction}{133}{subsection.4.0.3}
\contentsline {subsubsection}{\numberline {4.0.3.1}HOG Features}{133}{subsubsection.4.0.3.1}
\contentsline {subsubsection}{\numberline {4.0.3.2}CNN Features}{134}{subsubsection.4.0.3.2}
\contentsline {subsection}{\numberline {4.0.4}Algorithm Parameters}{135}{subsection.4.0.4}
\contentsline {subsection}{\numberline {4.0.5}Training and Testing Procedures}{136}{subsection.4.0.5}
\contentsline {paragraph}{Training}{136}{section*.62}
\contentsline {paragraph}{Out-of-Sample Testing}{136}{section*.63}
\contentsline {paragraph}{Evaluation Metrics}{137}{section*.64}
\contentsline {chapter}{\numberline {5}\uppercase {Preliminary Results}}{138}{chapter.5}
\contentsline {chapter}{\numberline {6}\uppercase {Future Tasks}}{139}{chapter.6}
\contentsline {subsection}{\numberline {6.0.1}Overview of Tasks:}{139}{subsection.6.0.1}
\contentsline {subsection}{\numberline {6.0.2}Tasks and Approximate Dates of Completion:}{139}{subsection.6.0.2}
\addvspace {10pt}\noindent {APPENDIX} \hfill \par 
