\BOOKMARK [0][-]{tableofcontents.0}{TABLE OF CONTENTS}{}% 1
\BOOKMARK [0][-]{chapter*.2}{LIST OF TABLES}{}% 2
\BOOKMARK [0][-]{chapter*.3}{LIST OF FIGURES}{}% 3
\BOOKMARK [0][-]{chapter*.5}{LIST OF ABBREVIATIONS}{}% 4
\BOOKMARK [0][-]{chapter*.6}{LIST OF SYMBOLS}{}% 5
\BOOKMARK [0][-]{chapter.1}{1 Introduction}{}% 6
\BOOKMARK [0][-]{chapter.2}{2 Background}{}% 7
\BOOKMARK [1][-]{section.2.1}{2.1 Multiple Instance Learning}{chapter.2}% 8
\BOOKMARK [2][-]{subsection.2.1.1}{2.1.1 Multiple Instance Learning with Manifold Bags}{section.2.1}% 9
\BOOKMARK [2][-]{subsection.2.1.2}{2.1.2 Tasks}{section.2.1}% 10
\BOOKMARK [2][-]{subsection.2.1.3}{2.1.3 Multiple Instance Classification}{section.2.1}% 11
\BOOKMARK [3][-]{subsubsection.2.1.3.1}{2.1.3.1 Space Paradigms}{subsection.2.1.3}% 12
\BOOKMARK [3][-]{subsubsection.2.1.3.2}{2.1.3.2 MIL Classification Approaches}{subsection.2.1.3}% 13
\BOOKMARK [2][-]{subsection.2.1.4}{2.1.4 Multiple Instance Boosting \(MIL-Boost\)}{section.2.1}% 14
\BOOKMARK [2][-]{subsection.2.1.5}{2.1.5 Multiple Instance Ranking}{section.2.1}% 15
\BOOKMARK [1][-]{section.2.2}{2.2 Manifold Learning}{chapter.2}% 16
\BOOKMARK [2][-]{subsection.2.2.1}{2.2.1 Definition and General Notation}{section.2.2}% 17
\BOOKMARK [2][-]{subsection.2.2.2}{2.2.2 Linear Manifold Learning}{section.2.2}% 18
\BOOKMARK [3][-]{subsubsection.2.2.2.1}{2.2.2.1 Principal Component Analysis \(PCA\)}{subsection.2.2.2}% 19
\BOOKMARK [3][-]{subsubsection.2.2.2.2}{2.2.2.2 Multi-Dimensional Scaling \(MDS\)}{subsection.2.2.2}% 20
\BOOKMARK [3][-]{subsubsection.2.2.2.3}{2.2.2.3 Nonnegative Matrix Factorization \(NMF\)}{subsection.2.2.2}% 21
\BOOKMARK [3][-]{subsubsection.2.2.2.4}{2.2.2.4 Fisher's Linear Discriminant Analysis \(LDA\)}{subsection.2.2.2}% 22
\BOOKMARK [2][-]{subsection.2.2.3}{2.2.3 Nonlinear Manifold Learning}{section.2.2}% 23
\BOOKMARK [3][-]{subsubsection.2.2.3.1}{2.2.3.1 Kernelization}{subsection.2.2.3}% 24
\BOOKMARK [3][-]{subsubsection.2.2.3.2}{2.2.3.2 Graph-based Methods}{subsection.2.2.3}% 25
\BOOKMARK [3][-]{subsubsection.2.2.3.3}{2.2.3.3 Isomap}{subsection.2.2.3}% 26
\BOOKMARK [3][-]{subsubsection.2.2.3.4}{2.2.3.4 Locally Linear Embedding \(LLE\)}{subsection.2.2.3}% 27
\BOOKMARK [3][-]{subsubsection.2.2.3.5}{2.2.3.5 Laplacian Eigenmaps \(LE\)}{subsection.2.2.3}% 28
\BOOKMARK [3][-]{subsubsection.2.2.3.6}{2.2.3.6 Hessian LLE}{subsection.2.2.3}% 29
\BOOKMARK [3][-]{subsubsection.2.2.3.7}{2.2.3.7 Local Tangent Space Alignment \(LTSA\)}{subsection.2.2.3}% 30
\BOOKMARK [3][-]{subsubsection.2.2.3.8}{2.2.3.8 Diffusion Maps}{subsection.2.2.3}% 31
\BOOKMARK [3][-]{subsubsection.2.2.3.9}{2.2.3.9 Sammon Mapping}{subsection.2.2.3}% 32
\BOOKMARK [3][-]{subsubsection.2.2.3.10}{2.2.3.10 Maximum Variance Unfolding \(MVU\)}{subsection.2.2.3}% 33
\BOOKMARK [2][-]{subsection.2.2.4}{2.2.4 Latent Variable Models}{section.2.2}% 34
\BOOKMARK [3][-]{subsubsection.2.2.4.1}{2.2.4.1 General Latent Variable Model \(GLVM\)}{subsection.2.2.4}% 35
\BOOKMARK [3][-]{subsubsection.2.2.4.2}{2.2.4.2 Generative Topographic Mapping \(GTM\)}{subsection.2.2.4}% 36
\BOOKMARK [2][-]{subsection.2.2.5}{2.2.5 Competitive Hebbian Learning}{section.2.2}% 37
\BOOKMARK [2][-]{subsection.2.2.6}{2.2.6 Principal Curves}{section.2.2}% 38
\BOOKMARK [2][-]{subsection.2.2.7}{2.2.7 Deep Learning}{section.2.2}% 39
\BOOKMARK [2][-]{subsection.2.2.8}{2.2.8 UMAP}{section.2.2}% 40
\BOOKMARK [2][-]{subsection.2.2.9}{2.2.9 Stochastic Neighbor Embedding \(SNE and t-SNE\)}{section.2.2}% 41
\BOOKMARK [3][-]{subsubsection.2.2.9.1}{2.2.9.1 Manifold Charting}{subsection.2.2.9}% 42
\BOOKMARK [2][-]{subsection.2.2.10}{2.2.10 NCA}{section.2.2}% 43
\BOOKMARK [3][-]{subsubsection.2.2.10.1}{2.2.10.1 M3DNet}{subsection.2.2.10}% 44
\BOOKMARK [3][-]{subsubsection.2.2.10.2}{2.2.10.2 Relations}{subsection.2.2.10}% 45
\BOOKMARK [3][-]{subsubsection.2.2.10.3}{2.2.10.3 Strengths and Weaknesses}{subsection.2.2.10}% 46
\BOOKMARK [2][-]{subsection.2.2.11}{2.2.11 Overview of Unsupervised Manifold Learning Methods}{section.2.2}% 47
\BOOKMARK [1][-]{section.2.3}{2.3 Weakly Supervised Manifold Learning and Dimensionality Reduction}{chapter.2}% 48
\BOOKMARK [2][-]{subsection.2.3.1}{2.3.1 MIDR}{section.2.3}% 49
\BOOKMARK [2][-]{subsection.2.3.2}{2.3.2 MidLABS}{section.2.3}% 50
\BOOKMARK [2][-]{subsection.2.3.3}{2.3.3 MIDA}{section.2.3}% 51
\BOOKMARK [2][-]{subsection.2.3.4}{2.3.4 CLFDA}{section.2.3}% 52
\BOOKMARK [2][-]{subsection.2.3.5}{2.3.5 MI-FEAR}{section.2.3}% 53
\BOOKMARK [2][-]{subsection.2.3.6}{2.3.6 Comparison Table of MI Dimensionality Reduction Methods}{section.2.3}% 54
\BOOKMARK [2][-]{subsection.2.3.7}{2.3.7 General Weak Supervision}{section.2.3}% 55
\BOOKMARK [1][-]{section.2.4}{2.4 Metric Embedding}{chapter.2}% 56
\BOOKMARK [2][-]{subsection.2.4.1}{2.4.1 Ranking Loss}{section.2.4}% 57
\BOOKMARK [3][-]{subsubsection.2.4.1.1}{2.4.1.1 Contrastive Loss}{subsection.2.4.1}% 58
\BOOKMARK [3][-]{subsubsection.2.4.1.2}{2.4.1.2 Triplet Loss}{subsection.2.4.1}% 59
\BOOKMARK [2][-]{subsection.2.4.2}{2.4.2 Large-Margin K-Nearest Neighbors \(LMNN\)}{section.2.4}% 60
\BOOKMARK [2][-]{subsection.2.4.3}{2.4.3 Siamese Neural Networks}{section.2.4}% 61
\BOOKMARK [2][-]{subsection.2.4.4}{2.4.4 FaceNet}{section.2.4}% 62
\BOOKMARK [0][-]{chapter.3}{3 Technical Approach}{}% 63
\BOOKMARK [1][-]{section.3.1}{3.1 Preliminary Work}{chapter.3}% 64
\BOOKMARK [2][-]{subsection.3.1.1}{3.1.1 S-LE Algorithm Description}{section.3.1}% 65
\BOOKMARK [2][-]{subsection.3.1.2}{3.1.2 SE-Isomap Algorithm Description}{section.3.1}% 66
\BOOKMARK [2][-]{subsection.3.1.3}{3.1.3 Instance-Level Classification}{section.3.1}% 67
\BOOKMARK [1][-]{section.3.2}{3.2 Future Work}{chapter.3}% 68
\BOOKMARK [2][-]{subsection.3.2.1}{3.2.1 Instance Selection}{section.3.2}% 69
\BOOKMARK [2][-]{subsection.3.2.2}{3.2.2 Manifold Learning}{section.3.2}% 70
\BOOKMARK [2][-]{subsection.3.2.3}{3.2.3 Features}{section.3.2}% 71
\BOOKMARK [2][-]{subsection.3.2.4}{3.2.4 Metric Embedding}{section.3.2}% 72
\BOOKMARK [2][-]{subsection.3.2.5}{3.2.5 Out-of-Sample Testing}{section.3.2}% 73
\BOOKMARK [2][-]{subsection.3.2.6}{3.2.6 Comparison to SOA}{section.3.2}% 74
\BOOKMARK [1][-]{section.3.3}{3.3 Datasets}{chapter.3}% 75
\BOOKMARK [0][-]{chapter.4}{4 Experimental Design}{}% 76
\BOOKMARK [1][-]{subsection.4.0.1}{4.0.1 Overview}{chapter.4}% 77
\BOOKMARK [2][-]{subsection.4.0.2}{4.0.2 Description of Data}{subsection.4.0.1}% 78
\BOOKMARK [3][-]{subsubsection.4.0.2.1}{4.0.2.1 Quadratic Surfaces}{subsection.4.0.2}% 79
\BOOKMARK [3][-]{subsubsection.4.0.2.2}{4.0.2.2 DSIAC MS-003-DB}{subsection.4.0.2}% 80
\BOOKMARK [2][-]{subsection.4.0.3}{4.0.3 Feature Extraction}{subsection.4.0.1}% 81
\BOOKMARK [3][-]{subsubsection.4.0.3.1}{4.0.3.1 HOG Features}{subsection.4.0.3}% 82
\BOOKMARK [3][-]{subsubsection.4.0.3.2}{4.0.3.2 CNN Features}{subsection.4.0.3}% 83
\BOOKMARK [2][-]{subsection.4.0.4}{4.0.4 Algorithm Parameters}{subsection.4.0.1}% 84
\BOOKMARK [2][-]{subsection.4.0.5}{4.0.5 Training and Testing Procedures}{subsection.4.0.1}% 85
\BOOKMARK [0][-]{chapter.5}{5 Preliminary Results}{}% 86
\BOOKMARK [0][-]{chapter.6}{6 Future Tasks}{}% 87
\BOOKMARK [1][-]{subsection.6.0.1}{6.0.1 Overview of Tasks:}{chapter.6}% 88
\BOOKMARK [2][-]{subsection.6.0.2}{6.0.2 Tasks and Approximate Dates of Completion:}{subsection.6.0.1}% 89
